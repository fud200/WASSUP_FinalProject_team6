{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba04aa-0770-4820-a964-aaca4757bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.34:5000\n",
      "Press CTRL+C to quit\n",
      "192.168.0.34 - - [31/May/2024 09:11:06] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.0.34 - - [31/May/2024 09:11:06] \"GET /video_feed HTTP/1.1\" 200 -\n",
      "192.168.0.34 - - [31/May/2024 09:11:17] \"POST /chat HTTP/1.1\" 200 -\n",
      "192.168.0.34 - - [31/May/2024 09:11:26] \"POST /chat HTTP/1.1\" 200 -\n",
      "192.168.0.34 - - [31/May/2024 09:11:38] \"POST /chat HTTP/1.1\" 200 -\n",
      "[2024-05-31 09:12:05,784] ERROR in app: Exception on /chat [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "  File \"C:\\Users\\fud10\\AppData\\Local\\Temp\\ipykernel_15520\\2466137082.py\", line 121, in chat_response\n",
      "    response = chat.send_message(emotion_message)\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\generativeai\\generative_models.py\", line 496, in send_message\n",
      "    response = self.model.generate_content(\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\generativeai\\generative_models.py\", line 262, in generate_content\n",
      "    response = self._client.generate_content(\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py\", line 812, in generate_content\n",
      "    response = rpc(\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py\", line 131, in __call__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 293, in retry_wrapped_func\n",
      "    return retry_target(\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 153, in retry_target\n",
      "    _retry_error_helper(\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py\", line 212, in _retry_error_helper\n",
      "    raise final_exc from source_exc\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 144, in retry_target\n",
      "    result = target()\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\api_core\\timeout.py\", line 120, in func_with_timeout\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\fud10\\anaconda3\\envs\\khb\\lib\\site-packages\\google\\api_core\\grpc_helpers.py\", line 78, in error_remapped_callable\n",
      "    raise exceptions.from_grpc_error(exc) from exc\n",
      "google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\n",
      "192.168.0.34 - - [31/May/2024 09:12:05] \"POST /chat HTTP/1.1\" 500 -\n",
      "192.168.0.34 - - [31/May/2024 09:12:24] \"POST /chat HTTP/1.1\" 200 -\n",
      "192.168.0.34 - - [31/May/2024 09:12:41] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response, request, jsonify\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from vit_pytorch import ViT\n",
    "from torchvision.models import densenet121\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "import threading\n",
    "\n",
    "# Google API key 설정\n",
    "GOOGLE_API_KEY = \"Put your API key\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "# model_api = genai.GenerativeModel('gemini-pro')\n",
    "model_api = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "chat = model_api.start_chat(history=[])\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "num_classes = 4  # 감정 클래스 수\n",
    "\n",
    "# 데이터 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 모델 정의: DenseNet-121 + ViT\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.densenet = densenet121(pretrained=False)\n",
    "        num_ftrs = self.densenet.classifier.in_features\n",
    "        self.densenet.classifier = nn.Identity()  # Fully connected layer 제거\n",
    "        \n",
    "        self.vit = ViT(\n",
    "            image_size=224,\n",
    "            patch_size=32,\n",
    "            num_classes=1024,  # 중간 차원으로 1024 사용\n",
    "            dim=1024,\n",
    "            depth=6,\n",
    "            heads=16,\n",
    "            mlp_dim=2048,\n",
    "            dropout=0.1,\n",
    "            emb_dropout=0.1\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(num_ftrs + 1024, num_classes)  # 결합된 특성에 맞게 조정\n",
    "\n",
    "    def forward(self, x):\n",
    "        densenet_features = self.densenet(x)  # Shape: (batch_size, num_ftrs)\n",
    "        vit_features = self.vit(x)  # Shape: (batch_size, 1024)\n",
    "        combined_features = torch.cat((densenet_features, vit_features), dim=1)  # Shape: (batch_size, num_ftrs + 1024)\n",
    "        out = self.fc(combined_features)\n",
    "        return out\n",
    "\n",
    "# 모델 초기화 및 가중치 로드\n",
    "device = torch.device(\"cpu\")\n",
    "model = HybridModel(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load('best_hybrid_model_densenet.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# OpenCV 웹캠 초기화\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 감정 레이블\n",
    "emotion_labels = ['anger', 'happy', 'panic', 'sadness']\n",
    "\n",
    "# 전역 변수로 감정 상태 저장\n",
    "global_emotions = []\n",
    "\n",
    "# 감정 및 프레임 감지 함수\n",
    "def detect_emotion(frame):\n",
    "    global global_emotions\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    emotions = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "        face_img = transform(face_img).unsqueeze(0).to(device)\n",
    "        outputs = model(face_img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        emotion = emotion_labels[predicted.item()]\n",
    "        emotions.append(emotion)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, emotion, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    global_emotions = emotions\n",
    "    return emotions, frame\n",
    "\n",
    "# 얼굴 감지기 로드\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Flask 애플리케이션 생성\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 웹캠 프레임 생성기\n",
    "def gen_frames():  \n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        emotions, frame = detect_emotion(frame)\n",
    "        \n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "# 채팅 입력을 처리하는 함수\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat_response():\n",
    "    global global_emotions\n",
    "    chat_input = request.form['message']\n",
    "    if global_emotions:\n",
    "        # emotion_message = f\"My emotion today is {', '.join(global_emotions)}. {chat_input}\"\n",
    "        emotion_message = f\"My emotion seems like {', '.join(global_emotions)}. {chat_input} \\n\\n 무조건 한국어로 대화하면 좋겠어요. 심리 상담가처럼 응답해줬으면 좋겠어요. 길게 정보를 나열하기 보다는 대화를 통해 자연스럽게 정보 전달이 되었으면 좋겠어요.\"\n",
    "        response = chat.send_message(emotion_message)\n",
    "        return jsonify({'response': response.text})\n",
    "    else:\n",
    "        return jsonify({'response': 'No emotion detected'})\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612dbdb3-8852-42d8-a5c2-d82087fddc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something:\n",
      "Recognizing...\n",
      "Recognized Text: hi I'm glad hi\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def check_microphone():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something:\")\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            print(\"Recognizing...\")\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"Recognized Text: {text}\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand the audio.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_microphone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc8487e-4c6b-4c88-a927-f177b9c9e5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
